{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "くえり https://cir.nii.ac.jp/opensearch/all?count=5&sortorder=0&format=json&q=%E5%A4%A7%E8%A6%8F%E6%A8%A1%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB\n",
      "<Response [200]>\n",
      "{\"@context\":{\"@vocab\":\"http://purl.org/rss/1.0/\",\"rdf\":\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\",\"rdfs\":\"http://www.w3.org/2000/01/rdf-schema#\",\"dc\":\"http://purl.org/dc/elements/1.1/\",\"prism\":\"http://prismstandard.org/namespaces/basic/2.0/\",\"ndl\":\"http://ndl.go.jp/dcndl/terms\",\"opensearch\":\"http://a9.com/-/spec/opensearch/1.1/\",\"cir\":\"https://cir.nii.ac.jp/schema/1.0/\",\"@language\":\"ja\"},\"@id\":\"https://cir.nii.ac.jp/opensearch/all?count=5&sortorder=0&format=json&q=%E5%A4%A7%E8%A6%8F%E6%A8%A1%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB\",\"@type\":\"channel\",\"title\":\"CiNii Research all - 5 0 json 大規模言語モデル\",\"description\":\"CiNii Research all - 5 0 json 大規模言語モデル\",\"link\":{\"@id\":\"https://cir.nii.ac.jp/opensearch/all?count=5&sortorder=0&format=json&q=%E5%A4%A7%E8%A6%8F%E6%A8%A1%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB\"},\"dc:date\":\"2023-12-09T21:22:57.018+09:00\",\"opensearch:totalResults\":135,\"opensearch:startIndex\":1,\"opensearch:itemsPerPage\":5,\"items\":[{\"@id\":\"https://cir.nii.ac.jp/crid/1520016748557827584\",\"@type\":\"item\",\"title\":\"PFRの家庭向けロボ、大規模言語モデル経由で操作 生成コードはLuaを採用、将来はマルチモーダル型へ\",\"link\":{\"@id\":\"https://cir.nii.ac.jp/crid/1520016748557827584\"},\"rdfs:seeAlso\":{\"@id\":\"https://cir.nii.ac.jp/crid/1520016748557827584.json\"},\"dc:publisher\":\"日経BP社\",\"dc:type\":\"Article\",\"prism:publicationName\":\"Nikkei robotics\",\"prism:issn\":\"21895783\",\"prism:number\":\"101\",\"prism:startingPage\":\"30\",\"prism:endingPage\":\"32\",\"prism:publicationDate\":\"2023-12\",\"description\":\"PFNはLLMを自社開発しており、2023年9月には130億パラメータのLLM「PLaMo-13B」を公開した（pp.40-42の記事を参照）注1）。製品版のカチャカにLLMを適用する場合は、この自社開発のLLMを利用する見込みだが、今回のデモではLLMには米OpenAI社の「GPT-4」を利用した。カチャカ…\",\"dc:identifier\":[{\"@type\":\"cir:NDL_BIB_ID\",\"@value\":\"033168166\"},{\"@type\":\"cir:URI\",\"@value\":\"http://bizboard.nikkeibp.co.jp/houjin/cgi-bin/nsearch/md_pdf.pl/0000496838.pdf?NEWS_ID=0000496838&CONTENTS=1&bt=ROB&SYSTEM_ID=HO\"}],\"dc:source\":[{\"@id\":\"http://bizboard.nikkeibp.co.jp/houjin/cgi-bin/nsearch/md_pdf.pl/0000496838.pdf?NEWS_ID=0000496838&CONTENTS=1&bt=ROB&SYSTEM_ID=HO\"}]},{\"@id\":\"https://cir.nii.ac.jp/crid/1520016748559385472\",\"@type\":\"item\",\"title\":\"LINEヤフーが人体CG向け生成AI技術 役割を指定して2人の相互動作を出力\",\"link\":{\"@id\":\"https://cir.nii.ac.jp/crid/1520016748559385472\"},\"rdfs:seeAlso\":{\"@id\":\"https://cir.nii.ac.jp/crid/1520016748559385472.json\"},\"dc:publisher\":\"日経BP社\",\"dc:type\":\"Article\",\"prism:publicationName\":\"Nikkei robotics\",\"prism:issn\":\"21895783\",\"prism:number\":\"101\",\"prism:startingPage\":\"24\",\"prism:endingPage\":\"29\",\"prism:publicationDate\":\"2023-12\",\"description\":\"文章や画像、動画といった多彩なコンテンツを人の指示に応じて出力する生成AIの技術が、すさまじい勢いで進化している。研究開発の進展に加えて応用先の開拓も活発だ。様々な業務への適用はもちろん、代表的な生成AIである大規模言語モデル（LLM）をロボット…\",\"dc:identifier\":[{\"@type\":\"cir:NDL_BIB_ID\",\"@value\":\"033168165\"},{\"@type\":\"cir:URI\",\"@value\":\"http://bizboard.nikkeibp.co.jp/houjin/cgi-bin/nsearch/md_pdf.pl/0000496837.pdf?NEWS_ID=0000496837&CONTENTS=1&bt=ROB&SYSTEM_ID=HO\"}],\"dc:source\":[{\"@id\":\"http://bizboard.nikkeibp.co.jp/houjin/cgi-bin/nsearch/md_pdf.pl/0000496837.pdf?NEWS_ID=0000496837&CONTENTS=1&bt=ROB&SYSTEM_ID=HO\"}]},{\"@id\":\"https://cir.nii.ac.jp/crid/1520298223536110976\",\"@type\":\"item\",\"title\":\"〔第１０１回〕　ＣＥＡＴＥＣ2023：大規模言語モデルＰＬａＭｏ、　ＭＮ−Ｃｏｒｅ、3Ｄ空間スキャン\",\"link\":{\"@id\":\"https://cir.nii.ac.jp/crid/1520298223536110976\"},\"rdfs:seeAlso\":{\"@id\":\"https://cir.nii.ac.jp/crid/1520298223536110976.json\"},\"dc:creator\":[\"岡野原 大輔\"],\"dc:publisher\":\"日経BP社\",\"dc:type\":\"Article\",\"prism:publicationName\":\"Nikkei robotics\",\"prism:issn\":\"21895783\",\"prism:number\":\"101\",\"prism:startingPage\":\"40\",\"prism:endingPage\":\"42\",\"prism:publicationDate\":\"2023-12\",\"description\":\"PFNは2023年9月末にPLaMo-13B1）（技術解説ブログ2））という大規模言語モデルをOSSライセンスで公開した。PLaMo-13Bは現在公開されている他の同サイズのモデルと比較し、日英2言語合わせた能力で世界トップレベルの高い性能を示している。　PLaMo-13Bは約130億（13B）パラ…\",\"dc:identifier\":[{\"@type\":\"cir:NDL_BIB_ID\",\"@value\":\"033168169\"},{\"@type\":\"cir:URI\",\"@value\":\"http://bizboard.nikkeibp.co.jp/houjin/cgi-bin/nsearch/md_pdf.pl/0000496842.pdf?NEWS_ID=0000496842&CONTENTS=1&bt=ROB&SYSTEM_ID=HO\"}],\"dc:source\":[{\"@id\":\"http://bizboard.nikkeibp.co.jp/houjin/cgi-bin/nsearch/md_pdf.pl/0000496842.pdf?NEWS_ID=0000496842&CONTENTS=1&bt=ROB&SYSTEM_ID=HO\"}]},{\"@id\":\"https://cir.nii.ac.jp/crid/1520579698510631168\",\"@type\":\"item\",\"title\":\"ロボの大規模言語モデル応用が次のフェーズへ 動作計画の拘束条件をLLMで生成、学習データ不要\",\"link\":{\"@id\":\"https://cir.nii.ac.jp/crid/1520579698510631168\"},\"rdfs:seeAlso\":{\"@id\":\"https://cir.nii.ac.jp/crid/1520579698510631168.json\"},\"dc:publisher\":\"日経BP社\",\"dc:type\":\"Article\",\"prism:publicationName\":\"Nikkei robotics\",\"prism:issn\":\"21895783\",\"prism:number\":\"101\",\"prism:startingPage\":\"3\",\"prism:endingPage\":\"13\",\"prism:publicationDate\":\"2023-12\",\"description\":\"大規模言語モデル（LLM：large　language　model）をロボットの行動生成AIに応用する試みが、新たなフェーズに入ってきた。LLMのロボットアームへの応用についてはここ1〜2年、米グーグルが活発に取り組んでおり、「SayCan」1）や「RT-2」2）といった技術を先駆的に開発…\",\"dc:identifier\":[{\"@type\":\"cir:NDL_BIB_ID\",\"@value\":\"033168163\"},{\"@type\":\"cir:URI\",\"@value\":\"http://bizboard.nikkeibp.co.jp/houjin/cgi-bin/nsearch/md_pdf.pl/0000496835.pdf?NEWS_ID=0000496835&CONTENTS=1&bt=ROB&SYSTEM_ID=HO\"}],\"dc:source\":[{\"@id\":\"http://bizboard.nikkeibp.co.jp/houjin/cgi-bin/nsearch/md_pdf.pl/0000496835.pdf?NEWS_ID=0000496835&CONTENTS=1&bt=ROB&SYSTEM_ID=HO\"}]},{\"@id\":\"https://cir.nii.ac.jp/crid/1390861184043719936\",\"@type\":\"item\",\"title\":\"類似文書検索と大規模言語モデルを用いた事故記録の解析\",\"link\":{\"@id\":\"https://cir.nii.ac.jp/crid/1390861184043719936\"},\"rdfs:seeAlso\":{\"@id\":\"https://cir.nii.ac.jp/crid/1390861184043719936.json\"},\"dc:creator\":[\"竹平 航平\",\"福田 賢一郎\"],\"dc:publisher\":\"一般社団法人 人工知能学会\",\"dc:type\":\"Article\",\"prism:publicationName\":\"人工知能学会第二種研究会資料\",\"prism:issn\":\"2436-5556\",\"prism:volume\":\"2023\",\"prism:number\":\"SAI-048\",\"prism:startingPage\":\"05\",\"prism:publicationDate\":\"2023-11-24\",\"dc:identifier\":[{\"@type\":\"cir:DOI\",\"@value\":\"10.11517/jsaisigtwo.2023.sai-048_05\"}]}]}\n",
      "['PFRの家庭向けロボ、大規模言語モデル経由で操作 生成コードはLuaを採用、将来はマルチモーダル型へ', 'LINEヤフーが人体CG向け生成AI技術 役割を指定して2人の相互動作を出力', '〔第１０１回〕\\u3000ＣＥＡＴＥＣ2023：大規模言語モデルＰＬａＭｏ、\\u3000ＭＮ−Ｃｏｒｅ、3Ｄ空間スキャン', 'ロボの大規模言語モデル応用が次のフェーズへ 動作計画の拘束条件をLLMで生成、学習データ不要', '類似文書検索と大規模言語モデルを用いた事故記録の解析']\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks.manager import CallbackManagerForToolRun, AsyncCallbackManagerForToolRun\n",
    "from typing import Optional, Type, Callable\n",
    "import requests\n",
    "import json\n",
    "from urllib.parse import quote\n",
    "\n",
    "# WebサーバのAPIエンドポイント\n",
    "url = \"https://cir.nii.ac.jp/opensearch/all?count=5&sortorder=0&format=json&q=\"\n",
    "\n",
    "# エンドポイントにPOSTリクエストを送信\n",
    "def _run(url, query: str, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:\n",
    "    query2 = url + quote(query)  #.replace(\"'\", '\"').encode('utf-8')\n",
    "    print(\"くえり\", query2)\n",
    "    # query_dict = json.loads(query)\n",
    "    response = requests.get(query2)  # .post(url) # +  \"get_topic\", query_dict)\n",
    "    print(response)\n",
    "    topic_content = response.text\n",
    "    print(topic_content)\n",
    "    return topic_content\n",
    "\n",
    "# 非同期実行関数の定義は必須\n",
    "# async def _run(url, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None) -> str:\n",
    "#     raise NotImplementedError(\"ListTopicTool does not support async\")\n",
    "\n",
    "result = _run(url, \"大規模言語モデル\")\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "data = json.loads(result)  \n",
    "for x in data:\n",
    "    id = data['items']\n",
    "title_list = []\n",
    "for titles in id:\n",
    "    # print(titles['title'])\n",
    "    title_list.append(titles['title'])\n",
    "print(title_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\onowa\\miniconda3\\envs\\vir_env\\lib\\site-packages\\langchain\\utils\\utils.py:159: UserWarning: WARNING! input is not default parameter.\n",
      "                input was transferred to model_kwargs.\n",
      "                Please confirm that input is what you intended.\n",
      "  warnings.warn(\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mあなたの仕事は与えられた文章から重要なエッセンスを抽出することです。文章が与えられた場合、文章に関する内容についてのエッセンスを箇条書きにして、日本語で書き出してください。\n",
      "\n",
      "文章:PFRの家庭向けロボ、大規模言語モデル経由で操作 生成コードはLuaを採用、将来はマルチモーダル型へ\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mあなたの仕事は与えられた文章から重要なエッセンスを抽出することです。文章が与えられた場合、文章に関する内容についてのエッセンスを箇条書きにして、日本語で書き出してください。\n",
      "\n",
      "文章:LINEヤフーが人体CG向け生成AI技術 役割を指定して2人の相互動作を出力\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mあなたの仕事は与えられた文章から重要なエッセンスを抽出することです。文章が与えられた場合、文章に関する内容についてのエッセンスを箇条書きにして、日本語で書き出してください。\n",
      "\n",
      "文章:〔第１０１回〕　ＣＥＡＴＥＣ2023：大規模言語モデルＰＬａＭｏ、　ＭＮ−Ｃｏｒｅ、3Ｄ空間スキャン\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mあなたの仕事は与えられた文章から重要なエッセンスを抽出することです。文章が与えられた場合、文章に関する内容についてのエッセンスを箇条書きにして、日本語で書き出してください。\n",
      "\n",
      "文章:ロボの大規模言語モデル応用が次のフェーズへ 動作計画の拘束条件をLLMで生成、学習データ不要\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mあなたの仕事は与えられた文章から重要なエッセンスを抽出することです。文章が与えられた場合、文章に関する内容についてのエッセンスを箇条書きにして、日本語で書き出してください。\n",
      "\n",
      "文章:類似文書検索と大規模言語モデルを用いた事故記録の解析\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mあなたの仕事は箇条書きのリストを整理することです。箇条書きのリストが与えられた場合、内容が重複する箇所はひとつの文章にまとめた箇条書きのリストを書き出してください。\n",
      "\n",
      "箇条書きのリスト:と発展\n",
      "\n",
      "可能\n",
      "\n",
      "\n",
      "\n",
      " 株式会社ZMPは、運行管理システム「Mission Control（MC2）」における機能向上の一環として、大規模言語モデル（LLM）を応用することで生成された動作プランが運行システムに準拠するかどうかを判定する仕組み「Rapid Planning Verification」（RPV）機能を開発しました。\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "LLMは、最大10兆件の詳細なデータに基づいて、さまざまな形式やレベルで情報を生成および解釈することができる機械学習アプローチであり、その技術は自然言語処理と人工知能（AI）に関連しています。\n",
      "\n",
      "LLMを活用した「RPV」の開発によって生成される動作プランにおける、運行管理システム「MC2」への準拠性や変化がなく安定的な運営を確保できます。\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain import hub\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.prompts import load_prompt\n",
    "\n",
    "llm = LlamaCpp(\n",
    "    model_path=\"llama.cpp/models/rinna-youri-7b-chat-q4_K_M.gguf\",\n",
    "    # model_path=r\"llama.cpp/cpp\\models\\llama-2-7b-chat.Q4_K_M.gguf\",\n",
    "    input={\n",
    "        \"max_tokens\": 32,\n",
    "        \"stop\": [\"System:\", \"User:\", \"Assistant:\", \"\\n\"],\n",
    "    },\n",
    "    verbose=True,\n",
    "    temperature=1,\n",
    "    n_ctx=2048\n",
    ")\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "# 分割した長文を書く文章ごとにDocumentオブジェクト化\n",
    "docs = [Document(page_content=t) for t in title_list]\n",
    "\n",
    "map_prompt_template_path = 'map_prompt.json'\n",
    "combine_prompt_template_path = 'combine_prompt.json'\n",
    "\n",
    "chain = load_summarize_chain(\n",
    "    llm,\n",
    "    chain_type=\"map_reduce\",\n",
    "    return_intermediate_steps=True,\n",
    "    verbose=True,\n",
    "    map_prompt=load_prompt(map_prompt_template_path), # load_promptはpromtの設定をファイルで読み込んでいる。json, py, yamlファイルで読み込める\n",
    "    combine_prompt=load_prompt(combine_prompt_template_path)\n",
    ")\n",
    "\n",
    "output = chain(\n",
    "    inputs=docs,\n",
    "    return_only_outputs=True,\n",
    ")[\"output_text\"]\n",
    "\n",
    "print(output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import AnalyzeDocumentChain\n",
    "\n",
    "# from langchain import OpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import AnalyzeDocumentChain\n",
    "import os\n",
    "\n",
    "# llm = OpenAI(temperature=0)\n",
    "\n",
    "qa_chain = load_qa_chain(llm, chain_type=\"map_reduce\")\n",
    "qa_document_chain = AnalyzeDocumentChain(combine_docs_chain=qa_chain)\n",
    "result = qa_document_chain.run(input_document=\"\".join(title_list), question=\"何についての記事ですか？\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llama.generate: prefix-match hit\n",
    " Science/Tech"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vir_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
